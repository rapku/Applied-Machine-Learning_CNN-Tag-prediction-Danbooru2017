{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storage_dir = 'D:/UMSI Classes/Fall2018/670/Project/danbooru2017/Selected/'\n",
    "# test_dir = 'D:/UMSI Classes/Fall2018/670/Project/danbooru2017/Test/'\n",
    "\n",
    "current = os.getcwd()\n",
    "\n",
    "storage_dir = os.path.join(current + '/Final model/Training/')\n",
    "test_dir =  os.path.join(current + '/Final model/Test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "taglist = ['1girl', 'long_hair', 'blush', 'smile', 'short_hair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('training.pkl', 'rb') as file:\n",
    "#     training_data = pickle.load(file)\n",
    "# with open('test.pkl', 'rb') as file:\n",
    "#     test_data = pickle.load(file)\n",
    "\n",
    "with open('trainingv2.pkl', 'rb') as file:\n",
    "    training_data = pickle.load(file)\n",
    "with open('testv2.pkl', 'rb') as file:\n",
    "    test_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = [[str(x[0])+'.jpg']+list(x[1]) for x in training_data]\n",
    "df_check = pd.DataFrame(check, columns = ['filename', '1girl', 'long_hair', 'blush', 'smile', 'short_hair'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rapha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "formatted_train = [[str(x[0])+'.jpg']+list(x[1]) for x in training_data]\n",
    "formatted_test = [[str(x[0])+'.jpg']+list(x[1]) for x in test_data]\n",
    "\n",
    "train, val = train_test_split(formatted_train, train_size=0.9, random_state=15)\n",
    "\n",
    "df_weeb_train = pd.DataFrame(train, columns = ['filename', '1girl', 'long_hair', 'blush', 'smile', 'short_hair'])\n",
    "df_weeb_val = pd.DataFrame(val, columns = ['filename', '1girl', 'long_hair', 'blush', 'smile', 'short_hair'])\n",
    "df_weeb_test = pd.DataFrame(formatted_test, columns = ['filename', '1girl', 'long_hair', 'blush', 'smile', 'short_hair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8853 images.\n",
      "Found 984 images.\n",
      "Found 982 images.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#Data augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   horizontal_flip=True,\n",
    "                                   rotation_range=25,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   width_shift_range=0.1)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# ['1girl', 'long_hair', 'blush', 'smile', 'short_hair']\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe = df_weeb_train,\n",
    "        directory = storage_dir,\n",
    "        x_col = 'filename',\n",
    "        y_col = taglist,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=100,\n",
    "        class_mode='other')\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe = df_weeb_val,\n",
    "        directory = storage_dir,\n",
    "        x_col = 'filename',\n",
    "        y_col = taglist,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=50,\n",
    "        class_mode='other')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe = df_weeb_test,\n",
    "        directory = test_dir,\n",
    "        x_col = 'filename',\n",
    "        y_col = taglist,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=50,\n",
    "        class_mode='other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model proper: 5 tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import callbacks\n",
    "\n",
    "callback = [EarlyStopping(monitor='val_loss', patience=2), ModelCheckpoint(filepath='weeb_current.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(256, 256, 3)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(rate=0.15))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(rate=0.15))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(rate=0.4))\n",
    "\n",
    "model.add(layers.Dense(5, activation='relu'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr = 0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# danbooru_tags = model.load_weights('weeb_ec2_lastrun.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "danbooru_tags = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=150,\n",
    "#       callbacks=callback,\n",
    "      epochs=10,\n",
    "      validation_data=val_generator,\n",
    "      validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weeb_ec2_lastrun.h5') #3 layers 32, 164, 128 conv, dropout 0.15 for each, dropout 0.4, 256 dense to 5 dense\n",
    "with open('weeb_ec2.history', 'wb') as file:\n",
    "    pickle.dump(danbooru_tags, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weeb_ec2: 15 epochs, 3 layers 32, 164, 128 conv, dropout 0.1 for each, dropout 0.5, 512 dense to 5 dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_LDAv2.pkl', 'rb') as file:\n",
    "    training_data_LDA = pickle.load(file)\n",
    "with open('test_LDAv2.pkl', 'rb') as file:\n",
    "    test_data_LDA = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rapha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "formatted_train_LDA = [[str(x[0])+'.jpg']+list(x[2]) for x in training_data_LDA]\n",
    "formatted_test_LDA = [[str(x[0])+'.jpg']+list(x[2]) for x in test_data_LDA]\n",
    "\n",
    "train2, val2 = train_test_split(formatted_train_LDA, train_size=0.9, random_state=15)\n",
    "\n",
    "df_weeb_train_LDA = pd.DataFrame(train2, columns = ['filename',0,1,2,3,4,5,6,7,8,9])\n",
    "df_weeb_val_LDA = pd.DataFrame(val2, columns = ['filename',0,1,2,3,4,5,6,7,8,9])\n",
    "df_weeb_test_LDA = pd.DataFrame(formatted_test_LDA, columns = ['filename',0,1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8853 images.\n",
      "Found 984 images.\n",
      "Found 982 images.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen_LDA = ImageDataGenerator(rescale=1./255, \n",
    "                                   horizontal_flip=True,\n",
    "                                   rotation_range=25,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   width_shift_range=0.1)\n",
    "\n",
    "val_datagen_LDA = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen_LDA = ImageDataGenerator(rescale=1./255)\n",
    "col_list = list(df_weeb_test.columns[1:])\n",
    "\n",
    "# ['1girl', 'long_hair', 'blush', 'smile', 'short_hair']\n",
    "\n",
    "train_generator_LDA = train_datagen_LDA.flow_from_dataframe(\n",
    "        dataframe = df_weeb_train_LDA,\n",
    "        directory = storage_dir,\n",
    "        x_col = 'filename',\n",
    "        y_col = [0,1,2,3,4,5,6,7,8,9],\n",
    "        target_size=(256, 256),\n",
    "        batch_size=20,\n",
    "        class_mode='other')\n",
    "\n",
    "val_generator_LDA = val_datagen_LDA.flow_from_dataframe(\n",
    "        dataframe = df_weeb_val_LDA,\n",
    "        directory = storage_dir,\n",
    "        x_col = 'filename',\n",
    "        y_col = [0,1,2,3,4,5,6,7,8,9],\n",
    "        target_size=(256, 256),\n",
    "        batch_size=20,\n",
    "        class_mode='other')\n",
    "\n",
    "test_generator_LDA = test_datagen_LDA.flow_from_dataframe(\n",
    "        dataframe = df_weeb_test_LDA,\n",
    "        directory = test_dir,\n",
    "        x_col = 'filename',\n",
    "        y_col = [0,1,2,3,4,5,6,7,8,9],\n",
    "        target_size=(256, 256),\n",
    "        batch_size=20,\n",
    "        class_mode='other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "model2 = models.Sequential()\n",
    "\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256, 3)))\n",
    "\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Dropout(rate=0.15))\n",
    "\n",
    "model2.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Dropout(rate=0.15))\n",
    "\n",
    "model2.add(layers.Flatten())\n",
    "\n",
    "model2.add(layers.Dense(256, activation='relu'))\n",
    "model2.add(layers.Dropout(rate=0.4))\n",
    "\n",
    "model2.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='mean_squared_error',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeb_LDA = model2.fit_generator(\n",
    "      train_generator_LDA,\n",
    "      steps_per_epoch=150,\n",
    "      epochs=10,\n",
    "      validation_data=val_generator_LDA,\n",
    "      validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('weeb_LDA.h5')\n",
    "with open('weeb_LDA.history', 'wb') as file:\n",
    "    pickle.dump(weeb_LDA, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
